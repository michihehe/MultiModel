## 数据集

`yelp`

英文，关于餐厅和食品的评论，每个评论可能包括多张图片，共包含44305条文本评论，附带244569张图片

`MVSA`

《Sentiment Analysis on Multi-view Social Data, MultiMedia Modeling 》

twitter平台的图像文本对，一部分是MVSA-Single（MVSA-S）每个样本由一位标注者进行标注只包含一个情感标注标签，共4869个图像-文本对；另一部分是MVSA-Multiple，每个样本由三位标注者进行标注包含三个情感标注标签，共19598个图像-文本对

`Multi-ZOL` 

《Multi-Interactive Memory Network for  Aspect Based Multimodal SentimentAnalysis》

关于手机的中文评论，带图片的5288条多模态评论

`twitter-15,17`

《 A Fair and Comprehensive Comparison of Multimodal Tweet Sentiment Analysis Methods》



## 论文

### Tmobert

《Adapting BERT for Target-Oriented Multimodal Sentiment Classification》

![image-20211022090522690](多模态综述.assets/image-20211022090522690.png)

## 预训练模型

### viLbert

![image-20211109104149848](多模态综述.assets/image-20211109104149848.png)

![image-20211109104207238](多模态综述.assets/image-20211109104207238.png)



图片表示：

**训练**

掩码多模态建模：

多模态对齐预测：

VQA,VCR



### Lmxbert

《LXMERT: Learning Cross-Modality Encoder Representations from Transformers》

https://github.com/airsplay/lxmert#pre-training

![img](多模态综述.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYXNsaTEyMw==,size_16,color_FFFFFF,t_70.png)



### Uniter（2020.6）

《UNITER: UNiversal Image-TExt Representation Learning》

https://github.com/ChenRocks/UNITER

预训练任务：



### ernie-vil(2021)

![image-20211115194107561](多模态综述.assets/image-20211115194107561.png)



提出了前人工作忽略了在细粒度语义对齐，重点关注图片和文字之间的细粒度语义对齐，使模型专注于理解语义词在视觉和文本间建立语义联系

>  预训练数据集：Conceptual Captions  SBU Captions MS-COCO  Visual-Genome

> 测试的下游任务：VQA  VCR  RefCOCO+  Image-textRetrieval

添加场景图预测任务：包括实体预测， 属性预测， 关系预测任务



### CLIP

code https://github.com/openai/CLIP

对比学习

![image-20211112163010249](多模态综述.assets/image-20211112163010249.png)





### virtex









### ICMLM



